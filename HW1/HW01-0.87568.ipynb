{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz0_QVkxCrX3"
      },
      "source": [
        "# **Homework 1: COVID-19 Cases Prediction (Regression)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeZnPAiwDRWG"
      },
      "source": [
        "Author: Heng-Jui Chang\n",
        "\n",
        "Slides: https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.pdf  \n",
        "Video: TBA\n",
        "\n",
        "Objectives:\n",
        "* Solve a regression problem with deep neural networks (DNN).\n",
        "* Understand basic DNN training tips.\n",
        "* Get familiar with PyTorch.\n",
        "\n",
        "If any questions, please contact the TAs via TA hours, NTU COOL, or email.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx3x1nDkG-Uy"
      },
      "source": [
        "# **Download Data**\n",
        "\n",
        "\n",
        "If the Google drive links are dead, you can download data from [kaggle](https://www.kaggle.com/c/ml2021spring-hw1/data), and upload data manually to the workspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMj55YDKG6ch",
        "outputId": "38c8f8cf-712a-4d94-e622-fb8fb1aa5270"
      },
      "source": [
        "tr_path = 'covid.train.csv'  # path to training data\n",
        "tt_path = 'covid.test.csv'   # path to testing data\n",
        "\n",
        "!gdown --id '19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF' --output covid.train.csv\n",
        "!gdown --id '1CE240jLm2npU-tdz81-oVKEF3T2yfT1O' --output covid.test.csv"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF\n",
            "To: /content/covid.train.csv\n",
            "100% 2.00M/2.00M [00:00<00:00, 31.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CE240jLm2npU-tdz81-oVKEF3T2yfT1O\n",
            "To: /content/covid.test.csv\n",
            "100% 651k/651k [00:00<00:00, 10.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS_4-77xHk44"
      },
      "source": [
        "# **Import Some Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-onQd4JNA5H"
      },
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# For data preprocess\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "myseed = 42069  # set a random seed for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtE3b6JEH7rw"
      },
      "source": [
        "# **Some Utilities**\n",
        "\n",
        "You do not need to modify this part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWMT3uf1NGQp"
      },
      "source": [
        "def get_device():\n",
        "    ''' Get device (if GPU is available, use GPU) '''\n",
        "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def plot_learning_curve(loss_record, title=''):\n",
        "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
        "    total_steps = len(loss_record['train'])\n",
        "    x_1 = range(total_steps)\n",
        "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
        "    figure(figsize=(6, 4))\n",
        "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
        "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n",
        "    plt.ylim(0.0, 5.)\n",
        "    plt.xlabel('Training steps')\n",
        "    plt.ylabel('MSE loss')\n",
        "    plt.title('Learning curve of {}'.format(title))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n",
        "    ''' Plot prediction of your DNN '''\n",
        "    if preds is None or targets is None:\n",
        "        model.eval()\n",
        "        preds, targets = [], []\n",
        "        for x, y in dv_set:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(x)\n",
        "                preds.append(pred.detach().cpu())\n",
        "                targets.append(y.detach().cpu())\n",
        "        preds = torch.cat(preds, dim=0).numpy()\n",
        "        targets = torch.cat(targets, dim=0).numpy()\n",
        "\n",
        "    figure(figsize=(5, 5))\n",
        "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
        "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
        "    plt.xlim(-0.2, lim)\n",
        "    plt.ylim(-0.2, lim)\n",
        "    plt.xlabel('ground truth value')\n",
        "    plt.ylabel('predicted value')\n",
        "    plt.title('Ground Truth v.s. Prediction')\n",
        "    plt.show()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39U_XFX6KOoj"
      },
      "source": [
        "# **Preprocess**\n",
        "\n",
        "We have three kinds of datasets:\n",
        "* `train`: for training\n",
        "* `dev`: for validation\n",
        "* `test`: for testing (w/o target value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ-MdwpLL7Dt"
      },
      "source": [
        "## **Dataset**\n",
        "\n",
        "The `COVID19Dataset` below does:\n",
        "* read `.csv` files\n",
        "* extract features\n",
        "* split `covid.train.csv` into train/dev sets\n",
        "* normalize features\n",
        "\n",
        "Finishing `TODO` below might make you pass medium baseline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zlpIp9ANJRU"
      },
      "source": [
        "class COVID19Dataset(Dataset):\n",
        "    ''' Dataset for loading and preprocessing the COVID19 dataset '''\n",
        "    def __init__(self,\n",
        "                 path,\n",
        "                 mode='train',\n",
        "                 target_only=False):\n",
        "        self.mode = mode\n",
        "\n",
        "        # Read data into numpy arrays\n",
        "        with open(path, 'r') as fp:\n",
        "            data = list(csv.reader(fp))\n",
        "            data = np.array(data[1:])[:, 1:].astype(float)\n",
        "        \n",
        "        if not target_only:\n",
        "            feats = list(range(93))\n",
        "        else:\n",
        "            # TODO: Using 40 states & 2 tested_positive features (indices = 57 & 75)\n",
        "            feats = [40, 41, 42, 43, 57,\\\n",
        "                     58, 59, 60, 61, 75,\\\n",
        "                     76, 77, 78, 79]\n",
        "            pass\n",
        "\n",
        "        if mode == 'test':\n",
        "            # Testing data\n",
        "            # data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))\n",
        "            data = data[:, feats]\n",
        "            self.data = torch.FloatTensor(data)\n",
        "        else:\n",
        "            # Training data (train/dev sets)\n",
        "            # data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))\n",
        "            target = data[:, -1]\n",
        "            data = data[:, feats]\n",
        "            \n",
        "            # Splitting training data into train & dev sets\n",
        "            if mode == 'train':\n",
        "                indices = [i for i in range(len(data)) if i % 10 != 1]\n",
        "            elif mode == 'dev':\n",
        "                indices = [i for i in range(len(data)) if i % 10 == 1]\n",
        "            \n",
        "            # Convert data into PyTorch tensors\n",
        "            self.data = torch.FloatTensor(data[indices])\n",
        "            self.target = torch.FloatTensor(target[indices])\n",
        "\n",
        "        # Normalize features (you may remove this part to see what will happen)\n",
        "\n",
        "       # self.data[:, :] = \\\n",
        "       #     (self.data[:, :] - self.data[:, :].mean(dim=0, keepdim=True)) \\\n",
        "       #     / self.data[:, :].std(dim=0, keepdim=True)\n",
        "\n",
        "        self.dim = self.data.shape[1]\n",
        "\n",
        "        print('Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'\n",
        "              .format(mode, len(self.data), self.dim))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Returns one sample at a time\n",
        "        if self.mode in ['train', 'dev']:\n",
        "            # For training\n",
        "            return self.data[index], self.target[index]\n",
        "        else:\n",
        "            # For testing (no target)\n",
        "            return self.data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        # Returns the size of the dataset\n",
        "        return len(self.data)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlhTlkE7MDo3"
      },
      "source": [
        "## **DataLoader**\n",
        "\n",
        "A `DataLoader` loads data from a given `Dataset` into batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlhLk5t6MBX3"
      },
      "source": [
        "def prep_dataloader(path, mode, batch_size, n_jobs=0, target_only=False):\n",
        "    ''' Generates a dataset, then is put into a dataloader. '''\n",
        "    dataset = COVID19Dataset(path, mode=mode, target_only=target_only)  # Construct dataset\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size,\n",
        "        shuffle=(mode == 'train'), drop_last=False,\n",
        "        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n",
        "    return dataloader"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGuycwR0MeQB"
      },
      "source": [
        "# **Deep Neural Network**\n",
        "\n",
        "`NeuralNet` is an `nn.Module` designed for regression.\n",
        "The DNN consists of 2 fully-connected layers with ReLU activation.\n",
        "This module also included a function `cal_loss` for calculating loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49-uXYovOAI0"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    ''' A simple fully-connected deep neural network '''\n",
        "    def __init__(self, input_dim):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        # Define your neural network here\n",
        "        # TODO: How to modify this model to achieve better performance?\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 10),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(10, 1)\n",
        "        )\n",
        "\n",
        "        # Mean squared error loss\n",
        "        self.criterion = nn.MSELoss(reduction='mean')\n",
        "\n",
        "    def forward(self, x):\n",
        "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "    def cal_loss(self, pred, target):\n",
        "        ''' Calculate loss '''\n",
        "        # TODO: you may implement L2 regularization here\n",
        "\n",
        "        l2_loss = self.criterion(pred, target)\n",
        "        l2_lambda = 0.00005\n",
        "        l2_reg = torch.tensor(0.).to('cuda')\n",
        "        for param in model.parameters():\n",
        "            l2_reg += torch.norm(param)\n",
        "        l2_loss += l2_lambda * l2_reg  \n",
        "\n",
        "        return l2_loss    #self.criterion(pred, target)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvFWVjZ5Nvga"
      },
      "source": [
        "# **Train/Dev/Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAM8QecJOyqn"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOqcmYzMO7jB"
      },
      "source": [
        "def train(tr_set, dv_set, model, config, device):\n",
        "    ''' DNN training '''\n",
        "\n",
        "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
        "\n",
        "    # Setup optimizer\n",
        "\n",
        "    optimizer = getattr(torch.optim, config['optimizer'])(\n",
        "       model.parameters(), **config['optim_hparas'])\n",
        "    \n",
        "    # optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, weight_decay = 0.00001)\n",
        "\n",
        "    min_mse = 1000.\n",
        "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
        "    early_stop_cnt = 0\n",
        "    epoch = 0\n",
        "    while epoch < n_epochs:\n",
        "        model.train()                           # set model to training mode\n",
        "        for x, y in tr_set:                     # iterate through the dataloader\n",
        "            optimizer.zero_grad()               # set gradient to zero\n",
        "            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "            mse_loss.backward()                 # compute gradient (backpropagation)\n",
        "            optimizer.step()                    # update model with optimizer\n",
        "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
        "\n",
        "        # After each epoch, test your model on the validation (development) set.\n",
        "        dev_mse = dev(dv_set, model, device)\n",
        "        if dev_mse < min_mse:\n",
        "            # Save model if your model improved\n",
        "            min_mse = dev_mse\n",
        "            print('Saving model (epoch = {:4d}, loss = {:.4f})'\n",
        "                .format(epoch + 1, min_mse))\n",
        "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
        "            early_stop_cnt = 0\n",
        "        else:\n",
        "            early_stop_cnt += 1\n",
        "\n",
        "        epoch += 1\n",
        "        loss_record['dev'].append(dev_mse)\n",
        "        if early_stop_cnt > config['early_stop']:\n",
        "            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n",
        "            break\n",
        "\n",
        "    print('Finished training after {} epochs'.format(epoch))\n",
        "    return min_mse, loss_record"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hSd4Bn3O2PL"
      },
      "source": [
        "## **Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrxrD3YsN3U2"
      },
      "source": [
        "def dev(dv_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    total_loss = 0\n",
        "    for x, y in dv_set:                         # iterate through the dataloader\n",
        "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
        "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
        "\n",
        "    return total_loss"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0pdrhQAO41L"
      },
      "source": [
        "## **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSBMRFlYN5tB"
      },
      "source": [
        "def test(tt_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    preds = []\n",
        "    for x in tt_set:                            # iterate through the dataloader\n",
        "        x = x.to(device)                        # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            preds.append(pred.detach().cpu())   # collect prediction\n",
        "    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n",
        "    return preds"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvckkF5dvf0j"
      },
      "source": [
        "# **Setup Hyper-parameters**\n",
        "\n",
        "`config` contains hyper-parameters for training and the path to save your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPXpdumwPjE7"
      },
      "source": [
        "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
        "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
        "target_only = True                  # TODO: Using 40 states & 2 tested_positive features\n",
        "\n",
        "# TODO: How to tune these hyper-parameters to improve your model's performance?\n",
        "config = {\n",
        "    'n_epochs': 10000,                # maximum number of epochs\n",
        "    'batch_size': 32,                # mini-batch size for dataloader\n",
        "    'optimizer': 'AdamW',            # optimization algorithm (optimizer in torch.optim)\n",
        "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "        'lr': 0.0001,                # learning rate of SGD\n",
        "        'weight_decay': 0.0001\n",
        "    #   'momentum': 0.9              # momentum for SGD\n",
        "    },\n",
        "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
        "    'save_path': 'models/model.pth'  # your model will be saved here\n",
        "}"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j1eOV3TOH-j"
      },
      "source": [
        "# **Load data and model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNrYBMmePLKm",
        "outputId": "4446fe3f-8acb-477f-852c-9117f950b4ca"
      },
      "source": [
        "tr_set = prep_dataloader(tr_path, 'train', config['batch_size'], target_only=target_only)\n",
        "dv_set = prep_dataloader(tr_path, 'dev', config['batch_size'], target_only=target_only)\n",
        "tt_set = prep_dataloader(tt_path, 'test', config['batch_size'], target_only=target_only)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 14)\n",
            "Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 14)\n",
            "Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHylSirLP9oh"
      },
      "source": [
        "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX2B_zgSOPTJ"
      },
      "source": [
        "# **Start Training!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrEbUxazQAAZ",
        "outputId": "75c1d5cb-82f8-4473-efe2-d6258ce85e71"
      },
      "source": [
        "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model (epoch =    1, loss = 188.4321)\n",
            "Saving model (epoch =    2, loss = 155.2859)\n",
            "Saving model (epoch =    3, loss = 111.3409)\n",
            "Saving model (epoch =    4, loss = 79.7293)\n",
            "Saving model (epoch =    5, loss = 56.4003)\n",
            "Saving model (epoch =    6, loss = 39.8114)\n",
            "Saving model (epoch =    7, loss = 28.6478)\n",
            "Saving model (epoch =    8, loss = 21.7962)\n",
            "Saving model (epoch =    9, loss = 17.9295)\n",
            "Saving model (epoch =   10, loss = 15.9581)\n",
            "Saving model (epoch =   11, loss = 15.0016)\n",
            "Saving model (epoch =   12, loss = 14.5550)\n",
            "Saving model (epoch =   13, loss = 14.3113)\n",
            "Saving model (epoch =   14, loss = 14.1472)\n",
            "Saving model (epoch =   15, loss = 14.0122)\n",
            "Saving model (epoch =   16, loss = 13.8884)\n",
            "Saving model (epoch =   17, loss = 13.7702)\n",
            "Saving model (epoch =   18, loss = 13.5826)\n",
            "Saving model (epoch =   19, loss = 13.2764)\n",
            "Saving model (epoch =   20, loss = 12.9976)\n",
            "Saving model (epoch =   21, loss = 12.7229)\n",
            "Saving model (epoch =   22, loss = 12.4508)\n",
            "Saving model (epoch =   23, loss = 12.1888)\n",
            "Saving model (epoch =   24, loss = 11.9079)\n",
            "Saving model (epoch =   25, loss = 11.6251)\n",
            "Saving model (epoch =   26, loss = 11.3451)\n",
            "Saving model (epoch =   27, loss = 11.0644)\n",
            "Saving model (epoch =   28, loss = 10.7779)\n",
            "Saving model (epoch =   29, loss = 10.4874)\n",
            "Saving model (epoch =   30, loss = 10.2013)\n",
            "Saving model (epoch =   31, loss = 9.9097)\n",
            "Saving model (epoch =   32, loss = 9.6189)\n",
            "Saving model (epoch =   33, loss = 9.3303)\n",
            "Saving model (epoch =   34, loss = 9.0447)\n",
            "Saving model (epoch =   35, loss = 8.7649)\n",
            "Saving model (epoch =   36, loss = 8.4726)\n",
            "Saving model (epoch =   37, loss = 8.1834)\n",
            "Saving model (epoch =   38, loss = 7.8998)\n",
            "Saving model (epoch =   39, loss = 7.6183)\n",
            "Saving model (epoch =   40, loss = 7.3480)\n",
            "Saving model (epoch =   41, loss = 7.0664)\n",
            "Saving model (epoch =   42, loss = 6.7891)\n",
            "Saving model (epoch =   43, loss = 6.5163)\n",
            "Saving model (epoch =   44, loss = 6.2532)\n",
            "Saving model (epoch =   45, loss = 5.9914)\n",
            "Saving model (epoch =   46, loss = 5.7373)\n",
            "Saving model (epoch =   47, loss = 5.4882)\n",
            "Saving model (epoch =   48, loss = 5.2496)\n",
            "Saving model (epoch =   49, loss = 5.0127)\n",
            "Saving model (epoch =   50, loss = 4.7943)\n",
            "Saving model (epoch =   51, loss = 4.5630)\n",
            "Saving model (epoch =   52, loss = 4.3461)\n",
            "Saving model (epoch =   53, loss = 4.1561)\n",
            "Saving model (epoch =   54, loss = 3.9456)\n",
            "Saving model (epoch =   55, loss = 3.7514)\n",
            "Saving model (epoch =   56, loss = 3.5814)\n",
            "Saving model (epoch =   57, loss = 3.3963)\n",
            "Saving model (epoch =   58, loss = 3.2327)\n",
            "Saving model (epoch =   59, loss = 3.0742)\n",
            "Saving model (epoch =   60, loss = 2.9329)\n",
            "Saving model (epoch =   61, loss = 2.7950)\n",
            "Saving model (epoch =   62, loss = 2.6627)\n",
            "Saving model (epoch =   63, loss = 2.5496)\n",
            "Saving model (epoch =   64, loss = 2.4314)\n",
            "Saving model (epoch =   65, loss = 2.3248)\n",
            "Saving model (epoch =   66, loss = 2.2228)\n",
            "Saving model (epoch =   67, loss = 2.1362)\n",
            "Saving model (epoch =   68, loss = 2.0535)\n",
            "Saving model (epoch =   69, loss = 1.9774)\n",
            "Saving model (epoch =   70, loss = 1.9088)\n",
            "Saving model (epoch =   71, loss = 1.8565)\n",
            "Saving model (epoch =   72, loss = 1.7971)\n",
            "Saving model (epoch =   73, loss = 1.7427)\n",
            "Saving model (epoch =   74, loss = 1.6965)\n",
            "Saving model (epoch =   75, loss = 1.6617)\n",
            "Saving model (epoch =   76, loss = 1.6231)\n",
            "Saving model (epoch =   77, loss = 1.5937)\n",
            "Saving model (epoch =   78, loss = 1.5671)\n",
            "Saving model (epoch =   79, loss = 1.5484)\n",
            "Saving model (epoch =   80, loss = 1.5252)\n",
            "Saving model (epoch =   81, loss = 1.5076)\n",
            "Saving model (epoch =   82, loss = 1.4931)\n",
            "Saving model (epoch =   83, loss = 1.4762)\n",
            "Saving model (epoch =   84, loss = 1.4663)\n",
            "Saving model (epoch =   85, loss = 1.4557)\n",
            "Saving model (epoch =   86, loss = 1.4481)\n",
            "Saving model (epoch =   87, loss = 1.4405)\n",
            "Saving model (epoch =   88, loss = 1.4342)\n",
            "Saving model (epoch =   89, loss = 1.4297)\n",
            "Saving model (epoch =   90, loss = 1.4256)\n",
            "Saving model (epoch =   91, loss = 1.4217)\n",
            "Saving model (epoch =   94, loss = 1.4147)\n",
            "Saving model (epoch =   95, loss = 1.4114)\n",
            "Saving model (epoch =   98, loss = 1.4064)\n",
            "Saving model (epoch =  100, loss = 1.4037)\n",
            "Saving model (epoch =  103, loss = 1.4000)\n",
            "Saving model (epoch =  104, loss = 1.3988)\n",
            "Saving model (epoch =  106, loss = 1.3966)\n",
            "Saving model (epoch =  107, loss = 1.3958)\n",
            "Saving model (epoch =  108, loss = 1.3943)\n",
            "Saving model (epoch =  109, loss = 1.3934)\n",
            "Saving model (epoch =  111, loss = 1.3925)\n",
            "Saving model (epoch =  112, loss = 1.3901)\n",
            "Saving model (epoch =  113, loss = 1.3901)\n",
            "Saving model (epoch =  115, loss = 1.3870)\n",
            "Saving model (epoch =  116, loss = 1.3865)\n",
            "Saving model (epoch =  117, loss = 1.3855)\n",
            "Saving model (epoch =  120, loss = 1.3841)\n",
            "Saving model (epoch =  121, loss = 1.3819)\n",
            "Saving model (epoch =  122, loss = 1.3792)\n",
            "Saving model (epoch =  125, loss = 1.3655)\n",
            "Saving model (epoch =  128, loss = 1.3572)\n",
            "Saving model (epoch =  129, loss = 1.3557)\n",
            "Saving model (epoch =  130, loss = 1.3530)\n",
            "Saving model (epoch =  131, loss = 1.3522)\n",
            "Saving model (epoch =  132, loss = 1.3489)\n",
            "Saving model (epoch =  136, loss = 1.3429)\n",
            "Saving model (epoch =  137, loss = 1.3419)\n",
            "Saving model (epoch =  140, loss = 1.3352)\n",
            "Saving model (epoch =  141, loss = 1.3325)\n",
            "Saving model (epoch =  142, loss = 1.3319)\n",
            "Saving model (epoch =  143, loss = 1.3291)\n",
            "Saving model (epoch =  146, loss = 1.3249)\n",
            "Saving model (epoch =  147, loss = 1.3233)\n",
            "Saving model (epoch =  148, loss = 1.3210)\n",
            "Saving model (epoch =  150, loss = 1.3191)\n",
            "Saving model (epoch =  153, loss = 1.3133)\n",
            "Saving model (epoch =  154, loss = 1.3118)\n",
            "Saving model (epoch =  157, loss = 1.3096)\n",
            "Saving model (epoch =  158, loss = 1.3057)\n",
            "Saving model (epoch =  159, loss = 1.3041)\n",
            "Saving model (epoch =  160, loss = 1.3025)\n",
            "Saving model (epoch =  162, loss = 1.2996)\n",
            "Saving model (epoch =  164, loss = 1.2973)\n",
            "Saving model (epoch =  165, loss = 1.2973)\n",
            "Saving model (epoch =  166, loss = 1.2956)\n",
            "Saving model (epoch =  167, loss = 1.2925)\n",
            "Saving model (epoch =  169, loss = 1.2895)\n",
            "Saving model (epoch =  172, loss = 1.2861)\n",
            "Saving model (epoch =  173, loss = 1.2840)\n",
            "Saving model (epoch =  176, loss = 1.2801)\n",
            "Saving model (epoch =  179, loss = 1.2767)\n",
            "Saving model (epoch =  180, loss = 1.2755)\n",
            "Saving model (epoch =  181, loss = 1.2747)\n",
            "Saving model (epoch =  184, loss = 1.2725)\n",
            "Saving model (epoch =  186, loss = 1.2662)\n",
            "Saving model (epoch =  187, loss = 1.2650)\n",
            "Saving model (epoch =  188, loss = 1.2634)\n",
            "Saving model (epoch =  191, loss = 1.2611)\n",
            "Saving model (epoch =  193, loss = 1.2571)\n",
            "Saving model (epoch =  194, loss = 1.2553)\n",
            "Saving model (epoch =  197, loss = 1.2524)\n",
            "Saving model (epoch =  198, loss = 1.2511)\n",
            "Saving model (epoch =  199, loss = 1.2489)\n",
            "Saving model (epoch =  201, loss = 1.2472)\n",
            "Saving model (epoch =  202, loss = 1.2457)\n",
            "Saving model (epoch =  203, loss = 1.2441)\n",
            "Saving model (epoch =  205, loss = 1.2417)\n",
            "Saving model (epoch =  209, loss = 1.2403)\n",
            "Saving model (epoch =  210, loss = 1.2370)\n",
            "Saving model (epoch =  212, loss = 1.2348)\n",
            "Saving model (epoch =  213, loss = 1.2320)\n",
            "Saving model (epoch =  217, loss = 1.2271)\n",
            "Saving model (epoch =  218, loss = 1.2259)\n",
            "Saving model (epoch =  220, loss = 1.2239)\n",
            "Saving model (epoch =  221, loss = 1.2228)\n",
            "Saving model (epoch =  223, loss = 1.2219)\n",
            "Saving model (epoch =  224, loss = 1.2196)\n",
            "Saving model (epoch =  226, loss = 1.2171)\n",
            "Saving model (epoch =  229, loss = 1.2145)\n",
            "Saving model (epoch =  231, loss = 1.2121)\n",
            "Saving model (epoch =  232, loss = 1.2108)\n",
            "Saving model (epoch =  234, loss = 1.2092)\n",
            "Saving model (epoch =  235, loss = 1.2082)\n",
            "Saving model (epoch =  237, loss = 1.2058)\n",
            "Saving model (epoch =  240, loss = 1.2044)\n",
            "Saving model (epoch =  241, loss = 1.2026)\n",
            "Saving model (epoch =  242, loss = 1.2016)\n",
            "Saving model (epoch =  243, loss = 1.2008)\n",
            "Saving model (epoch =  245, loss = 1.1992)\n",
            "Saving model (epoch =  246, loss = 1.1980)\n",
            "Saving model (epoch =  248, loss = 1.1960)\n",
            "Saving model (epoch =  252, loss = 1.1926)\n",
            "Saving model (epoch =  255, loss = 1.1910)\n",
            "Saving model (epoch =  257, loss = 1.1886)\n",
            "Saving model (epoch =  265, loss = 1.1830)\n",
            "Saving model (epoch =  266, loss = 1.1818)\n",
            "Saving model (epoch =  272, loss = 1.1787)\n",
            "Saving model (epoch =  273, loss = 1.1769)\n",
            "Saving model (epoch =  275, loss = 1.1750)\n",
            "Saving model (epoch =  279, loss = 1.1729)\n",
            "Saving model (epoch =  281, loss = 1.1701)\n",
            "Saving model (epoch =  283, loss = 1.1686)\n",
            "Saving model (epoch =  285, loss = 1.1681)\n",
            "Saving model (epoch =  290, loss = 1.1638)\n",
            "Saving model (epoch =  291, loss = 1.1636)\n",
            "Saving model (epoch =  292, loss = 1.1630)\n",
            "Saving model (epoch =  293, loss = 1.1628)\n",
            "Saving model (epoch =  295, loss = 1.1620)\n",
            "Saving model (epoch =  296, loss = 1.1601)\n",
            "Saving model (epoch =  297, loss = 1.1597)\n",
            "Saving model (epoch =  298, loss = 1.1590)\n",
            "Saving model (epoch =  299, loss = 1.1587)\n",
            "Saving model (epoch =  300, loss = 1.1577)\n",
            "Saving model (epoch =  302, loss = 1.1576)\n",
            "Saving model (epoch =  304, loss = 1.1557)\n",
            "Saving model (epoch =  305, loss = 1.1550)\n",
            "Saving model (epoch =  312, loss = 1.1535)\n",
            "Saving model (epoch =  313, loss = 1.1524)\n",
            "Saving model (epoch =  316, loss = 1.1515)\n",
            "Saving model (epoch =  317, loss = 1.1504)\n",
            "Saving model (epoch =  318, loss = 1.1502)\n",
            "Saving model (epoch =  320, loss = 1.1488)\n",
            "Saving model (epoch =  321, loss = 1.1478)\n",
            "Saving model (epoch =  323, loss = 1.1459)\n",
            "Saving model (epoch =  327, loss = 1.1441)\n",
            "Saving model (epoch =  331, loss = 1.1419)\n",
            "Saving model (epoch =  340, loss = 1.1404)\n",
            "Saving model (epoch =  342, loss = 1.1376)\n",
            "Saving model (epoch =  344, loss = 1.1365)\n",
            "Saving model (epoch =  346, loss = 1.1361)\n",
            "Saving model (epoch =  347, loss = 1.1360)\n",
            "Saving model (epoch =  349, loss = 1.1357)\n",
            "Saving model (epoch =  351, loss = 1.1344)\n",
            "Saving model (epoch =  353, loss = 1.1341)\n",
            "Saving model (epoch =  358, loss = 1.1314)\n",
            "Saving model (epoch =  361, loss = 1.1309)\n",
            "Saving model (epoch =  362, loss = 1.1300)\n",
            "Saving model (epoch =  364, loss = 1.1299)\n",
            "Saving model (epoch =  367, loss = 1.1293)\n",
            "Saving model (epoch =  370, loss = 1.1290)\n",
            "Saving model (epoch =  372, loss = 1.1279)\n",
            "Saving model (epoch =  373, loss = 1.1264)\n",
            "Saving model (epoch =  375, loss = 1.1263)\n",
            "Saving model (epoch =  376, loss = 1.1255)\n",
            "Saving model (epoch =  384, loss = 1.1237)\n",
            "Saving model (epoch =  385, loss = 1.1230)\n",
            "Saving model (epoch =  388, loss = 1.1222)\n",
            "Saving model (epoch =  393, loss = 1.1216)\n",
            "Saving model (epoch =  399, loss = 1.1190)\n",
            "Saving model (epoch =  402, loss = 1.1190)\n",
            "Saving model (epoch =  403, loss = 1.1182)\n",
            "Saving model (epoch =  411, loss = 1.1166)\n",
            "Saving model (epoch =  416, loss = 1.1157)\n",
            "Saving model (epoch =  421, loss = 1.1150)\n",
            "Saving model (epoch =  422, loss = 1.1139)\n",
            "Saving model (epoch =  428, loss = 1.1129)\n",
            "Saving model (epoch =  431, loss = 1.1121)\n",
            "Saving model (epoch =  435, loss = 1.1118)\n",
            "Saving model (epoch =  439, loss = 1.1109)\n",
            "Saving model (epoch =  441, loss = 1.1103)\n",
            "Saving model (epoch =  446, loss = 1.1102)\n",
            "Saving model (epoch =  448, loss = 1.1101)\n",
            "Saving model (epoch =  453, loss = 1.1083)\n",
            "Saving model (epoch =  462, loss = 1.1079)\n",
            "Saving model (epoch =  463, loss = 1.1077)\n",
            "Saving model (epoch =  469, loss = 1.1065)\n",
            "Saving model (epoch =  472, loss = 1.1063)\n",
            "Saving model (epoch =  473, loss = 1.1061)\n",
            "Saving model (epoch =  474, loss = 1.1057)\n",
            "Saving model (epoch =  482, loss = 1.1049)\n",
            "Saving model (epoch =  487, loss = 1.1043)\n",
            "Saving model (epoch =  492, loss = 1.1038)\n",
            "Saving model (epoch =  497, loss = 1.1035)\n",
            "Saving model (epoch =  501, loss = 1.1034)\n",
            "Saving model (epoch =  506, loss = 1.1029)\n",
            "Saving model (epoch =  514, loss = 1.1027)\n",
            "Saving model (epoch =  520, loss = 1.1015)\n",
            "Saving model (epoch =  525, loss = 1.1012)\n",
            "Saving model (epoch =  536, loss = 1.1007)\n",
            "Saving model (epoch =  543, loss = 1.1001)\n",
            "Saving model (epoch =  545, loss = 1.0999)\n",
            "Saving model (epoch =  552, loss = 1.0999)\n",
            "Saving model (epoch =  554, loss = 1.0992)\n",
            "Saving model (epoch =  558, loss = 1.0989)\n",
            "Saving model (epoch =  561, loss = 1.0987)\n",
            "Saving model (epoch =  571, loss = 1.0986)\n",
            "Saving model (epoch =  583, loss = 1.0978)\n",
            "Saving model (epoch =  586, loss = 1.0975)\n",
            "Saving model (epoch =  588, loss = 1.0972)\n",
            "Saving model (epoch =  598, loss = 1.0965)\n",
            "Saving model (epoch =  599, loss = 1.0963)\n",
            "Saving model (epoch =  604, loss = 1.0960)\n",
            "Saving model (epoch =  607, loss = 1.0958)\n",
            "Saving model (epoch =  614, loss = 1.0955)\n",
            "Saving model (epoch =  618, loss = 1.0952)\n",
            "Saving model (epoch =  636, loss = 1.0946)\n",
            "Saving model (epoch =  639, loss = 1.0946)\n",
            "Saving model (epoch =  649, loss = 1.0939)\n",
            "Saving model (epoch =  662, loss = 1.0930)\n",
            "Saving model (epoch =  696, loss = 1.0923)\n",
            "Saving model (epoch =  703, loss = 1.0921)\n",
            "Saving model (epoch =  704, loss = 1.0920)\n",
            "Saving model (epoch =  706, loss = 1.0917)\n",
            "Saving model (epoch =  716, loss = 1.0913)\n",
            "Saving model (epoch =  717, loss = 1.0911)\n",
            "Saving model (epoch =  731, loss = 1.0911)\n",
            "Saving model (epoch =  738, loss = 1.0905)\n",
            "Saving model (epoch =  752, loss = 1.0902)\n",
            "Saving model (epoch =  762, loss = 1.0897)\n",
            "Saving model (epoch =  766, loss = 1.0897)\n",
            "Saving model (epoch =  769, loss = 1.0897)\n",
            "Saving model (epoch =  775, loss = 1.0894)\n",
            "Saving model (epoch =  787, loss = 1.0894)\n",
            "Saving model (epoch =  796, loss = 1.0891)\n",
            "Saving model (epoch =  798, loss = 1.0889)\n",
            "Saving model (epoch =  805, loss = 1.0886)\n",
            "Saving model (epoch =  815, loss = 1.0885)\n",
            "Saving model (epoch =  831, loss = 1.0881)\n",
            "Saving model (epoch =  843, loss = 1.0872)\n",
            "Saving model (epoch =  845, loss = 1.0871)\n",
            "Saving model (epoch =  858, loss = 1.0871)\n",
            "Saving model (epoch =  862, loss = 1.0870)\n",
            "Saving model (epoch =  871, loss = 1.0870)\n",
            "Saving model (epoch =  872, loss = 1.0868)\n",
            "Saving model (epoch =  877, loss = 1.0866)\n",
            "Saving model (epoch =  879, loss = 1.0865)\n",
            "Saving model (epoch =  887, loss = 1.0862)\n",
            "Saving model (epoch =  888, loss = 1.0862)\n",
            "Saving model (epoch =  891, loss = 1.0859)\n",
            "Saving model (epoch =  911, loss = 1.0855)\n",
            "Saving model (epoch =  935, loss = 1.0852)\n",
            "Saving model (epoch =  940, loss = 1.0851)\n",
            "Saving model (epoch =  949, loss = 1.0848)\n",
            "Saving model (epoch =  959, loss = 1.0847)\n",
            "Saving model (epoch =  978, loss = 1.0845)\n",
            "Saving model (epoch =  987, loss = 1.0844)\n",
            "Saving model (epoch = 1009, loss = 1.0834)\n",
            "Saving model (epoch = 1022, loss = 1.0834)\n",
            "Saving model (epoch = 1035, loss = 1.0831)\n",
            "Saving model (epoch = 1037, loss = 1.0831)\n",
            "Saving model (epoch = 1049, loss = 1.0827)\n",
            "Saving model (epoch = 1056, loss = 1.0826)\n",
            "Saving model (epoch = 1058, loss = 1.0825)\n",
            "Saving model (epoch = 1068, loss = 1.0821)\n",
            "Saving model (epoch = 1076, loss = 1.0820)\n",
            "Saving model (epoch = 1082, loss = 1.0820)\n",
            "Saving model (epoch = 1085, loss = 1.0817)\n",
            "Saving model (epoch = 1108, loss = 1.0817)\n",
            "Saving model (epoch = 1117, loss = 1.0814)\n",
            "Saving model (epoch = 1141, loss = 1.0809)\n",
            "Saving model (epoch = 1154, loss = 1.0806)\n",
            "Saving model (epoch = 1163, loss = 1.0806)\n",
            "Saving model (epoch = 1174, loss = 1.0804)\n",
            "Saving model (epoch = 1195, loss = 1.0802)\n",
            "Saving model (epoch = 1200, loss = 1.0800)\n",
            "Saving model (epoch = 1211, loss = 1.0800)\n",
            "Saving model (epoch = 1213, loss = 1.0799)\n",
            "Saving model (epoch = 1221, loss = 1.0797)\n",
            "Saving model (epoch = 1245, loss = 1.0795)\n",
            "Saving model (epoch = 1251, loss = 1.0795)\n",
            "Saving model (epoch = 1253, loss = 1.0791)\n",
            "Saving model (epoch = 1265, loss = 1.0789)\n",
            "Saving model (epoch = 1269, loss = 1.0787)\n",
            "Saving model (epoch = 1298, loss = 1.0786)\n",
            "Saving model (epoch = 1317, loss = 1.0784)\n",
            "Saving model (epoch = 1330, loss = 1.0784)\n",
            "Saving model (epoch = 1332, loss = 1.0782)\n",
            "Saving model (epoch = 1348, loss = 1.0779)\n",
            "Saving model (epoch = 1352, loss = 1.0778)\n",
            "Saving model (epoch = 1354, loss = 1.0777)\n",
            "Saving model (epoch = 1365, loss = 1.0777)\n",
            "Saving model (epoch = 1373, loss = 1.0776)\n",
            "Saving model (epoch = 1387, loss = 1.0773)\n",
            "Saving model (epoch = 1397, loss = 1.0772)\n",
            "Saving model (epoch = 1408, loss = 1.0772)\n",
            "Saving model (epoch = 1419, loss = 1.0766)\n",
            "Saving model (epoch = 1458, loss = 1.0766)\n",
            "Saving model (epoch = 1462, loss = 1.0765)\n",
            "Saving model (epoch = 1470, loss = 1.0763)\n",
            "Saving model (epoch = 1474, loss = 1.0761)\n",
            "Saving model (epoch = 1497, loss = 1.0761)\n",
            "Saving model (epoch = 1505, loss = 1.0759)\n",
            "Saving model (epoch = 1507, loss = 1.0759)\n",
            "Saving model (epoch = 1510, loss = 1.0757)\n",
            "Saving model (epoch = 1514, loss = 1.0757)\n",
            "Saving model (epoch = 1523, loss = 1.0755)\n",
            "Saving model (epoch = 1533, loss = 1.0754)\n",
            "Saving model (epoch = 1537, loss = 1.0754)\n",
            "Saving model (epoch = 1550, loss = 1.0753)\n",
            "Saving model (epoch = 1567, loss = 1.0751)\n",
            "Saving model (epoch = 1605, loss = 1.0750)\n",
            "Saving model (epoch = 1607, loss = 1.0750)\n",
            "Saving model (epoch = 1617, loss = 1.0749)\n",
            "Saving model (epoch = 1629, loss = 1.0745)\n",
            "Saving model (epoch = 1631, loss = 1.0744)\n",
            "Saving model (epoch = 1671, loss = 1.0743)\n",
            "Saving model (epoch = 1683, loss = 1.0740)\n",
            "Saving model (epoch = 1693, loss = 1.0739)\n",
            "Saving model (epoch = 1704, loss = 1.0739)\n",
            "Saving model (epoch = 1708, loss = 1.0739)\n",
            "Saving model (epoch = 1713, loss = 1.0738)\n",
            "Saving model (epoch = 1717, loss = 1.0738)\n",
            "Saving model (epoch = 1731, loss = 1.0738)\n",
            "Saving model (epoch = 1748, loss = 1.0733)\n",
            "Saving model (epoch = 1776, loss = 1.0732)\n",
            "Saving model (epoch = 1805, loss = 1.0728)\n",
            "Saving model (epoch = 1810, loss = 1.0728)\n",
            "Saving model (epoch = 1811, loss = 1.0725)\n",
            "Saving model (epoch = 1831, loss = 1.0724)\n",
            "Saving model (epoch = 1835, loss = 1.0724)\n",
            "Saving model (epoch = 1862, loss = 1.0724)\n",
            "Saving model (epoch = 1876, loss = 1.0723)\n",
            "Saving model (epoch = 1888, loss = 1.0721)\n",
            "Saving model (epoch = 1889, loss = 1.0718)\n",
            "Saving model (epoch = 1892, loss = 1.0717)\n",
            "Saving model (epoch = 1902, loss = 1.0711)\n",
            "Saving model (epoch = 1917, loss = 1.0709)\n",
            "Saving model (epoch = 1920, loss = 1.0706)\n",
            "Saving model (epoch = 1929, loss = 1.0705)\n",
            "Saving model (epoch = 1935, loss = 1.0704)\n",
            "Saving model (epoch = 1969, loss = 1.0701)\n",
            "Saving model (epoch = 1978, loss = 1.0698)\n",
            "Saving model (epoch = 2005, loss = 1.0697)\n",
            "Saving model (epoch = 2007, loss = 1.0697)\n",
            "Saving model (epoch = 2018, loss = 1.0695)\n",
            "Saving model (epoch = 2027, loss = 1.0694)\n",
            "Saving model (epoch = 2063, loss = 1.0694)\n",
            "Saving model (epoch = 2070, loss = 1.0689)\n",
            "Saving model (epoch = 2120, loss = 1.0688)\n",
            "Saving model (epoch = 2121, loss = 1.0688)\n",
            "Saving model (epoch = 2135, loss = 1.0687)\n",
            "Saving model (epoch = 2145, loss = 1.0687)\n",
            "Saving model (epoch = 2151, loss = 1.0685)\n",
            "Saving model (epoch = 2154, loss = 1.0684)\n",
            "Saving model (epoch = 2196, loss = 1.0683)\n",
            "Saving model (epoch = 2214, loss = 1.0683)\n",
            "Saving model (epoch = 2254, loss = 1.0682)\n",
            "Saving model (epoch = 2256, loss = 1.0680)\n",
            "Saving model (epoch = 2261, loss = 1.0679)\n",
            "Saving model (epoch = 2304, loss = 1.0677)\n",
            "Saving model (epoch = 2323, loss = 1.0675)\n",
            "Saving model (epoch = 2324, loss = 1.0674)\n",
            "Saving model (epoch = 2358, loss = 1.0672)\n",
            "Saving model (epoch = 2424, loss = 1.0669)\n",
            "Saving model (epoch = 2451, loss = 1.0667)\n",
            "Saving model (epoch = 2462, loss = 1.0667)\n",
            "Saving model (epoch = 2499, loss = 1.0667)\n",
            "Saving model (epoch = 2519, loss = 1.0665)\n",
            "Saving model (epoch = 2527, loss = 1.0663)\n",
            "Saving model (epoch = 2571, loss = 1.0662)\n",
            "Saving model (epoch = 2574, loss = 1.0662)\n",
            "Saving model (epoch = 2612, loss = 1.0661)\n",
            "Saving model (epoch = 2640, loss = 1.0661)\n",
            "Saving model (epoch = 2649, loss = 1.0660)\n",
            "Saving model (epoch = 2650, loss = 1.0659)\n",
            "Saving model (epoch = 2689, loss = 1.0658)\n",
            "Saving model (epoch = 2697, loss = 1.0656)\n",
            "Saving model (epoch = 2762, loss = 1.0655)\n",
            "Saving model (epoch = 2798, loss = 1.0654)\n",
            "Saving model (epoch = 2811, loss = 1.0650)\n",
            "Saving model (epoch = 2867, loss = 1.0649)\n",
            "Saving model (epoch = 2905, loss = 1.0649)\n",
            "Saving model (epoch = 2917, loss = 1.0648)\n",
            "Saving model (epoch = 2984, loss = 1.0646)\n",
            "Saving model (epoch = 2994, loss = 1.0646)\n",
            "Saving model (epoch = 3033, loss = 1.0645)\n",
            "Saving model (epoch = 3052, loss = 1.0643)\n",
            "Saving model (epoch = 3054, loss = 1.0641)\n",
            "Saving model (epoch = 3099, loss = 1.0641)\n",
            "Saving model (epoch = 3155, loss = 1.0640)\n",
            "Saving model (epoch = 3171, loss = 1.0639)\n",
            "Saving model (epoch = 3207, loss = 1.0637)\n",
            "Saving model (epoch = 3292, loss = 1.0636)\n",
            "Saving model (epoch = 3307, loss = 1.0636)\n",
            "Saving model (epoch = 3340, loss = 1.0635)\n",
            "Saving model (epoch = 3353, loss = 1.0634)\n",
            "Saving model (epoch = 3354, loss = 1.0632)\n",
            "Saving model (epoch = 3400, loss = 1.0632)\n",
            "Saving model (epoch = 3459, loss = 1.0632)\n",
            "Saving model (epoch = 3487, loss = 1.0630)\n",
            "Saving model (epoch = 3499, loss = 1.0629)\n",
            "Saving model (epoch = 3524, loss = 1.0628)\n",
            "Saving model (epoch = 3584, loss = 1.0627)\n",
            "Saving model (epoch = 3598, loss = 1.0626)\n",
            "Saving model (epoch = 3681, loss = 1.0625)\n",
            "Saving model (epoch = 3693, loss = 1.0624)\n",
            "Saving model (epoch = 3770, loss = 1.0622)\n",
            "Saving model (epoch = 3816, loss = 1.0622)\n",
            "Saving model (epoch = 3824, loss = 1.0621)\n",
            "Saving model (epoch = 3857, loss = 1.0620)\n",
            "Saving model (epoch = 3904, loss = 1.0619)\n",
            "Saving model (epoch = 3910, loss = 1.0616)\n",
            "Saving model (epoch = 3954, loss = 1.0616)\n",
            "Saving model (epoch = 4000, loss = 1.0616)\n",
            "Saving model (epoch = 4016, loss = 1.0615)\n",
            "Saving model (epoch = 4018, loss = 1.0615)\n",
            "Saving model (epoch = 4071, loss = 1.0615)\n",
            "Saving model (epoch = 4084, loss = 1.0614)\n",
            "Saving model (epoch = 4113, loss = 1.0613)\n",
            "Saving model (epoch = 4255, loss = 1.0611)\n",
            "Saving model (epoch = 4286, loss = 1.0611)\n",
            "Saving model (epoch = 4288, loss = 1.0610)\n",
            "Saving model (epoch = 4348, loss = 1.0610)\n",
            "Saving model (epoch = 4407, loss = 1.0610)\n",
            "Saving model (epoch = 4424, loss = 1.0610)\n",
            "Saving model (epoch = 4425, loss = 1.0608)\n",
            "Saving model (epoch = 4479, loss = 1.0607)\n",
            "Saving model (epoch = 4584, loss = 1.0607)\n",
            "Saving model (epoch = 4597, loss = 1.0605)\n",
            "Saving model (epoch = 4621, loss = 1.0603)\n",
            "Saving model (epoch = 4647, loss = 1.0602)\n",
            "Saving model (epoch = 4794, loss = 1.0602)\n",
            "Saving model (epoch = 4803, loss = 1.0601)\n",
            "Saving model (epoch = 4860, loss = 1.0601)\n",
            "Saving model (epoch = 4936, loss = 1.0600)\n",
            "Saving model (epoch = 4955, loss = 1.0600)\n",
            "Saving model (epoch = 4971, loss = 1.0599)\n",
            "Saving model (epoch = 4974, loss = 1.0598)\n",
            "Saving model (epoch = 4992, loss = 1.0596)\n",
            "Saving model (epoch = 5177, loss = 1.0596)\n",
            "Saving model (epoch = 5180, loss = 1.0596)\n",
            "Saving model (epoch = 5237, loss = 1.0594)\n",
            "Finished training after 5438 epochs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "hsNO9nnXQBvP",
        "outputId": "bf8ddd7c-197a-4624-a643-ffb32abbe523"
      },
      "source": [
        "plot_learning_curve(model_loss_record, title='deep model')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVfrA8e87IZBCqCJIEVBYgqggIPa6ugIq2Na29oKKrl3X8lvFtddV14K6YFkU7A0VRSmKKAqKiECAhEBCS4D0nsz5/XFvhkkyNZnJJDfv53ny5M69555z5s7MO2fOPfdcMcaglFLKeVyxroBSSqno0ACvlFIOpQFeKaUcSgO8Uko5lAZ4pZRyKA3wSinlUBrgVUSIyFEikhbrerQUInKEiKwTkWIROS2E9K+JyAPNUbfmIiILROSKENMaERkU7Tq1NRrgHUBEMkXkhFjWwRjznTFmSCzr0ML8C3jOGNPRGPNRrCuj2iYN8CokIhIX6zo0VTM/h/7AH81YnlINaIB3MBFxicgdIpIuIjtF5B0R6ea1/V0R2SYiBSLyrYgM89r2moi8KCKfi0gJcJz9S+FWEVlh7/O2iCTY6Y8VkWyv/f2mtbffLiJbRWSLiFwR6Ce6iHQTkVfttHki8pG9/hIRWVQvrScfH8/hVvv5xnmlP11EVoRyvHzU60oRWS8iu0TkExHpba9PB/YBPrW7aDr42PcgEflFRIpE5G0god72U0RkuYjki8hiETnQa1tvEXlfRHJFZIOIXO+1bYqIvGcf7yK7jOEBnoMRkcl2d1KRiNwvIvvaZRbax6B9sOdsbztRRNbYr/dzgNQr6zIRWW2/hl+KSH9/9VIRYozRv1b+B2QCJ/hYfwPwI9AX6AC8BMz02n4ZkGJvexpY7rXtNaAAOAKrIZBgl/MT0BvoBqwGrrbTHwtk16uTv7RjgW3AMCAJmAEYYJCf5/cZ8DbQFYgHjrHXXwIsqpfWk4+f55AOnOiV/l3gjlCOV71yjgd2ACPttP8Bvg32mtjb2gMbgZvs53MWUAU8YG8/CMgBDgHigIvt/DrYz2MZcI+dzz5ABnCSve8UO6+z7LxvBTYA8X7qYoCPgU7261EBfGPn2xlYBVwc7DkDewBFXuXeBFQDV9jbJwLrgaFAO+D/gMW+Xjf9i2BsiHUF9C8CL6L/AL8a+LPX473sD387H2m72B+yzvbj14A3fJRzgdfjx4Cp9vKxNAzw/tJOBx722jbI3wfcrrMb6Opj2yUED/D1n8MDwHR7OQUoAfo34nhNAx7zetzRTjsg0Gtibzsa2AKI17rF7A7wLwL319snDTgGK+hvqrftTuBVe3kK8KPXNhewFTjKT10McITX42XAP7wePwk8Hew5AxfVK1eAbHYH+C+Ay+vVq9Tr2GuAj8KfdtE4W3/gQ/tnfj5WAKsBeopInIg8YndHFGIFJLBaYrWyfOS5zWu5FOtD7o+/tL3r5e2rnFr9gF3GmLwAaQKpn/dbwBl2t8kZwC/GmI32Nr/Hy0e+vbFa4QAYY4qBnUCfEOrUG9hs7Mhm2+i13B+4pbYedl362fv1B3rX23ZXvTp6nrMxxo0VaHvj33av5TIfj71fN3/Puc5raj8372PfH3jGq867sL4EQjleqpHaxboCKqqygMuMMd/X3yAiF2L9bD4BK7h3BvKo228aralGt2J1g9TqFyBtFtBNRLoYY/LrbSvB6uIBQER6+di/znMwxqwSkY3AOOB8rIDvXZbP4+XDFqygVVt2MtAd2BzCvluBPiIiXkF+b6zuo9p6PGiMebD+jiJyGLDBGDM4QP79vNK7sI71lhDqFUyg57y1XrlC3de19jm9GYF6qBBpC9454kUkweuvHTAVeLD2ZJaI9BCRiXb6FKz+1p1YQfKhZqzrO8ClIjJURJKAf/pLaIzZivXz/gUR6Soi8SJytL35N2CYiIywT+BOCbH8t7D624/G6oOvFeh41TfTfg4j7F8DDwFLjDGZIZT/A1b/9PX28zkDGOO1/RXgahE5RCzJInKyiKRgndcoEpF/iEii/UtsfxE52Gv/USJyhv0euBHrdf4xhHoFE+g5f4b1WtSWez3g/YU7FbhT7BP5ItJZRP4agTqpADTAO8fnWD+na/+mAM8AnwBfiUgR1of8EDv9G1g/tzdjnUiLRAAIiTHmC+BZYD7Wibfasiv87HIhVl/vGqyTjzfa+azFGm/+NbAOWORn//pmYvVnzzPG7PBaH+h41X8OX2N9Mb2P1XrdFzg3lMKNMZVY3UOXYHVVnAN84LV9KXAl8BzWr6r1dlqMMTXAKcAIrJOnO4D/Yv0Cq/WxnWce1rE7wxhTFUrdgtTb73O2j+NfgUewGg2Dge+99v0QeBSYZXcJrsT6FaWiSOp2AyrV/ERkKNYHvoMxpjrW9WnNRGQK1snKC2JdFxV72oJXMSHW+PMOItIVq2X3qQZ3pSIrqgFerItdfrcv2FgazbJUq3MVVndLOtZIlWtiWx2lnCeqXTQikgmMrtfPqZRSqhloF41SSjlUtFvwG7DO5BvgJWPMyz7STAImASQnJ49KTU1tVFnlK/+gNCGBrJ570W/7VroOHIDEtfr5sZRSKqBly5btMMb08LUt2gG+jzFms4jsCcwF/m6M+dZf+tGjR5ulSxvXVb86dSi/DUrlxlvu5cmnH+Cc116hXdeujay5Ukq1DiKyzBgz2te2qHbRGGM22/9zgA+pezFHxIl90aIRCZJSKaWcL2oB3r76LqV2GfgL1ljnqBG3HeDRAK+UUtGci6Yn1sRNteW8ZYyZE8XycNndTW5twSulVPQCvDEmA/B7o4Fo8HTRuDTAK9VWVFVVkZ2dTXl5eayrElUJCQn07duX+Pj4kPdx1GyS2kWjVNuTnZ1NSkoKAwYMQBz6690Yw86dO8nOzmbgwIEh7+eocfB6klWptqe8vJzu3bs7NrgDiAjdu3cP+1eKswK80QCvVFvk5OBeqzHP0VEB3uXWk6xKKVXLUQFeu2iUUs0tPz+fF154Iez9xo8fT35+/ZuURZZjArwkJmoXjVKq2fkL8NXVgWe//vzzz+nSpUu0qgU4aBRNXMeOGuCVUs3ujjvuID09nREjRhAfH09CQgJdu3ZlzZo1rF27ltNOO42srCzKy8u54YYbmDRpEgADBgxg6dKlFBcXM27cOI488kgWL15Mnz59+Pjjj0lMTGxy3RwT4CUxEalyAxrglWqrtj30EBWr10Q0zw5DU+l1111+tz/yyCOsXLmS5cuXs2DBAk4++WRWrlzpGc44ffp0unXrRllZGQcffDBnnnkm3bt3r5PHunXrmDlzJq+88gpnn30277//Phdc0PSbcjkmwAO4jBXg9SSrUipWxowZU2es+rPPPsuHH34IQFZWFuvWrWsQ4AcOHMiIESMAGDVqFJmZmRGpi6MCvNgTYxpxzKkFpVQYArW0m0tycrJnecGCBXz99df88MMPJCUlceyxx/ocy96hQwfPclxcHGVlZRGpi6MioZjaLpoYV0Qp1WakpKRQVFTkc1tBQQFdu3YlKSmJNWvW8OOPPzZr3bQFr5RSTdC9e3eOOOII9t9/fxITE+nZs6dn29ixY5k6dSpDhw5lyJAhHHrooc1aN+cEePFqwce4KkqptuWtt97yub5Dhw588cUXPrfV9rPvsccerFy5eyb1W2+9NWL1ckxT15WcvHu6YJdjnpZSSjWaYyKhxLXTcfBKKeXFMQEevCYb0+mClVLKYQFeb/ihlFIezgrwXjf8cJeUxrg2SikVW44K8N73ZN35yisxro1SSsWWowK8dxeNqa6KcW2UUm3VlClTeOKJJ2JdDYcFeO+TrDoYXinVxjkzwItQ8sMPMa6NUqotefDBB/nTn/7EkUceSVpaGgDp6emMHTuWUaNGcdRRR7FmzRoKCgro378/brd1YWZJSQn9+vWjqiryvQ7OuZKVugHeVFbGuDZKqeb2z3XZrCyOzERdtfbvmMj9g/sGTLNs2TJmzZrF8uXLqa6uZuTIkYwaNYpJkyYxdepUBg8ezJIlS5g8eTLz5s1jxIgRLFy4kOOOO47Zs2dz0kknER8fH9F6g8MCvPdJVoz20Silmsd3333H6aefTlJSEgATJkygvLycxYsX89e//tWTrqKiAoBzzjmHt99+m+OOO45Zs2YxefLkqNTLUQG+zpWsGuCVanOCtbSbk9vtpkuXLixfvrzBtgkTJnDXXXexa9culi1bxvHHHx+VOji2D14DvFKquRx99NF89NFHlJWVUVRUxKeffkpSUhIDBw7k3XffBcAYw2+//QZAx44dOfjgg7nhhhs45ZRTiIuLi0q9nBvglVKqmYwcOZJzzjmH4cOHM27cOA4++GAA3nzzTaZNm8bw4cMZNmwYH3/8sWefc845hxkzZnDOOedErV7aRaOUUhFw9913c/fddzdYP2fOHJ/pzzrrLEyU45SjWvAus/um2xrelVJtnaMCfO0dndx6RyellHJagPe6J6t20SjVZkS7q6MlaMxzdFSAd3n64B31tJRSASQkJLBz505HB3ljDDt37iQhISGs/Rx1khW90EmpNqdv375kZ2eTm5sb66pEVUJCAn37hjfO31EBvrYFjwjY8zwopZwtPj6egQMHxroaLZKj+jJqR79rC14ppZohwItInIj8KiKzo10WgLjdGMBdqnd0Ukq1bc3Rgr8BWN0M5QDWxU7G5agfJkop1ShRjYQi0hc4GfhvNMupUybG6qJRSqk2LtpN3aeB2wG/ZzxFZJKILBWRpZE4C+5yG3b3xiulVNsVtQAvIqcAOcaYZYHSGWNeNsaMNsaM7tGjRwRK1ha8UkpBdFvwRwATRCQTmAUcLyIzolVYu+7dAWuopM4mqZRSUQzwxpg7jTF9jTEDgHOBecaYC6JVXpezzgRA3BrglVIKnDQO3h454+ska/natY6+jFkppXxplgBvjFlgjDmlOcpyGWNdyWor+eEHNkyYSP7b7zRH8Uop1WI4pwVfy9RtwVdu3AhA+epmG4qvlFItguMCvPdJ1pIff8TU1MS4RkopFRuOmmwM7CtZ7QC/6ZJLie/dO8Y1Ukqp2HBcC16MqXNHp6otW2JYG6WUih3HBXjrJGusa6GUUrHnmADf8aijrAWjV7IqpRQ4KMBLfDxgn2TVJrxSSjknwNcS48a4fAR4vdBJKdXGODDAU+ckq1JKtVWOi4Quo/diVUopcGCAB3DrHZ2UUsp5Ad5lrHuyKqVUW+e4AG9NF+y4p6WUUmFzXCQUDG5fo2iUUqqNcVyAdxk/92TVYZJKqTbGcQFer2RVSimL4wK83pNVKaUsjgvwogFeAZXZm6lIT491NZSKKUfPB6/arvQTTgBg6Bq9k5dqu7QFr5RSDuW4AO/Sk6xKKQU4MMBrC14ppSxtKMDrOHilVNvShgK8Ukq1LW0mwJvKSoxbpxJWqjUp+uYb8j/8KNbVaLUcN0zSZdw+T7IWfPwJAL0ffbS5q6SUaqTsa68DoMvpp8W4Jq2TA1vw+J1NsjbIK6VUW+DAAO+7Ba+UUm2N4wK8y918J1mNMZSnrW2Wslord0WFThmgVIw4L8Abd9i37CtdtoysyddiamrC2q9w9mw2TJxI0bx5Ye0Xiq333MvaQw6NeL6hKF22jIqMjIjktfXOu8g4+RRqCgsjkp9SKnTODPBhtuCzr7+B4nnzqMnLC2u/irQ0638UWqj577xDTUFBxPMNxca/XUDG+JMjklfJzz8B4C4vj0h+SqnQOS/Au43edFsppXBigG9EF41SSjmR4yKhuA3uIDfdrli3Lir95kop1ZJE7UInEUkAvgU62OW8Z4y5N1rl1YoL0oKvzssj49QJgI+5wsO8b6vR+7wqpVqwaLbgK4DjjTHDgRHAWBGJ+rAQlzvwSdaqjRsbrmzisErRcfdKBWXcbkp/+bXZyqvansPOadPbdEMsagHeWIrth/H2X9SPtARpwQd6g1VmZ0ejSjHjtuffKfnhh9iP12+7nzFl2/Xqq2w8/3xKFi9ulvI233QTOY8/TmUbvg4jqn3wIhInIsuBHGCuMWaJjzSTRGSpiCzNzc1tcpmuEPrga1XXGxa58bzzMZWVPtNWZGyg+Ntvm1y/5uKurCTtwOHkPPEkmy69jA0TJ/pNWzR/PlXbc6JSD0F/3USTu6SEtIPHUPzdolhXJaiKdesBqNq2vVnKcxcVAWBq2u4kg1EN8MaYGmPMCKAvMEZE9veR5mVjzGhjzOgePXo0uUyXcWNc/oNK2a+7W/DZV1/TYHv236/3uV/G+PFkTbqqyfVrLqasDID8994Lmjb7mslknndutKukoqAiPR13URG5zz4b66qoFiisAC8iLhHpFG4hxph8YD4wNtx9w+Vyu6kJ0IIvmjvXs1yZlWUteH0fFC9cGK2qBVSTn8+Gv569u07NrHrL1piUq5SKnqABXkTeEpFOIpIMrARWichtIezXQ0S62MuJwInAmqZWOBiXO3ALvr7ihQupyd3RuMIi2K9cOHcu5b//zo6XXopcpjFg3G69alX51oZPdsZKKC34/YwxhcBpwBfAQODCEPbbC5gvIiuAn7H64Gc3uqYhsm66HfoPk6yrrm5ymYVfzQ2eqI3Ieexx0kYchLuiItZVaRu8gma4cylFStX2MPvUddRZswklEsaLSDxWgP/EGFNFCG1XY8wKY8xBxpgDjTH7G2P+1dTKhsIaJhligI9Qi6J8xQrKfl8Zkbxau/wPPgDAaCu+0ap37aIiY0NY+5T//jtrhu1PTXFx8MQRVPzdItYfcyxF33zTrOWGwlRVWf8r225jI5RI+BKQCSQD34pIf6DFTg3oMmHMRRMgwBu3m9X7DWPXm2+GlJW7pITSpUvZdPkVbL3vvtDKb1MCf5mW/LiEgk+j/gOvVUg/4UQyxo9v1L7hTpjXVOV//AFA2W8rIpKfu7ycinXrQkpbnZcX8DaclZmZAOz877RIVK1VChoJjTHPGmP6GGPG22PbNwLHNUPdGsXljsxcNKa6Gtxuch4JcIu/el8QGy+4kJLvvyd/5qwmle0uKWnS/i1KiD/HN11yCVtuC3pqp1mtPexwcp97vtnLdZeWAlBT7KD3QYi23P4PMk6dEPSXSNXWraw77HB2hnDOyl1eFqnqtTqhnGS9wT7JKiIyTUR+AY5vhro1SmOmC24s7xE5EWMMebPe9rnJXVJC3rvvhndlnp7YarSavDx2PPdczMov+KjhzaZrCgpIHzuOcnuq6hbz+oZUj+BpSpcutVIGOYdTbff7Fy1YEEK5bVcoTd3L7JOsfwG6Yp1gfSSqtWqC5pwuOJI/h0OZ7mDbww+z7Z/3UPrjj6FkGIFa7ebvAjAncldUkPvCC7Guhk8lixdTmZnJjhenArD98SdiWyH7fbbzlVfC2CdKdWmF1h56GDunvxq1/EOJhLUvx3jgf8aYP2jBL1FYLfgQWh2mqqrFfNhrdu4CwF3WvD85K7OzWXPgcFanDqXGvjowZC2lhRmGXdOns+PZ/8S6GiEpW7YspHRF8+e3iqtd25qa/HxyHnssavmHEuCXichXWAH+SxFJAVrstb8SoT54b7tef8OzvP3hh/0UHNqXiqmqara5OCKlYv16z3JVI+frMc3wpVSTn9+kY1u9YwfVubm4y5w3Aij7mslkXXllrKvhYaqrA54gbWuiNQ9WKJHwcuAO4GBjTCnQHrg0KrWJgGDTBXtrTNvSO9h723bPPSHtn/P002y67HL/k541olKmpobVqUPZOW16g23ucFvcUZI+dlzUy8i6+ho2XXZ5o09SrzvyKNYddXSEa+Vf8cKFFH/7LSU/NpiiyRKj38kZp05g8+23h5a4kV2Ba/Y/gI3nnR/WPtW5uaxOHUrxd98FTFc4Zw6rU4c2ql6xkn7CiVHJN5RRNG6suWT+T0SeAA43xkRmTFQUBJsu2Ju7qfc89Sqn0tc0xD5U2uOba/Lr9d/X5mWMzw/NrhlvUrZ8OQDZk6/1jPEFe8QPkPP44216atTae+PG6oKfcNTk55N11dVkTbqKTZdcEvqOzfD6VqxbR+Enn0Y83/rvzbLffgtr/9prTfLefMuzrmrzlgbpCj//on7BYZXjy9Z/3sPWKVOanE9zC3rDDxF5BDgYqB0Qfr2IHGaMuSuqNWskCWccvB8V69bRvn//3Sv8vUHCeONsuuxyytPSSDzwwAbbSn780dMtUPj55z5HEGx/4IE6j6tzc4nv3btBuuL580k5vgUNcmqFVy26iyP/q8cYQ+5TT9Fh0CBcKSkkHnBA8J0CHTt/m5oYzKp37gxvhxBeXndZGXh1x0Ty/gk1Oxo5zUgQpqoKd1kZcZ2sqbfy330XgL1aWZAP5Y5O44ERdkseEXkd+BVokQE+zu3GhDFVgS8Zp05ggP2CAo360LjLypCEBMpXrGDbAw9S/vvvgBWAvVVmb2bTJbt7vIINDwul3JgKcqyKvvkGV3JHkg89pJkqFD6/XSZNYMrK2PnKfz2PB3/XtKmnTRTOE7grKlh3xJERz3ft4UdgysroNOFUAMpXrQ6yR4Q14gsl+6abKP76m4Z3fWtlQo2EXbyWO0ejIpFS24Jv6o+y6u3bmrR/2kEj2fHc82y7/wFPcPfmLim1/0fpYpZItpwb0yr0UX5Fxgayr70uvC6JKKnavJm0g8d4rnYMpHrHjpjMreOrpVvbzVG8YIGnyy4c7vJyv++5cIfCFi1YQMHHH/vdnv/hR2RdfU2DE+xVOVGeDz7M974xhvyPPqrzGhd/3fKmXmiMUAL8w8CvIvKa3XpfBjwY3Wo1nsv+KRjNi522P/xISJfVF872nyacqzbL7MvBvVXn5LD9sccblLPlllup3LQp5LybU2Mvvw/E1NSw4cyzKJo3P3hiLwWffY67qIj8999vuLHee2fdkUeRdfkVIeddnpYWvXMhXtmWrQj/VFj6SWNJGzU6IlXJvvoaKtf7v1vS1jvvpNj7QqQIHZLiBQuoiWDDqGTRIrbecSc5Tz7Z6DxKf/6Zqm1WozDn30+Tdc3kSFWvSUI5yToTOBT4AHgfOMwY4/tSyxYgzg7wTe2m8VZ/JMqu11+3AnQz9S9nnnlWw3Xnnseu6dMpWbyYivSMOtsKGnmCrGL9+shd0BSFAFeRnk5RvS4ud1ER5X/8wZY77wy+/7p1rE4dStnKhl+YwZQuXUrxd4vY9YbvUVS1Spb8xIaJp5E3I8gcRjE6N1Ed7syPUeD9y6QxrwXA9vsfCJ6otjyEmqIidrz0cp2hmTX5+awZOYriBdY9IKqbcEe5jRdeRMbJpwCw86WXGnTFxorfPngRGVlvVe1Azd4i0tsY80v0qtV4YgcWt8sF7saPpihb0bBbpb7a0SvRtObA4QG3V21tWleSt4xTTqXL2WcHThQsMNXbXp3TtFsBFs2bT/sBA+iwz0DPByhYv6i/8xhF8xdY/7+cgyslwH1r/DzF2nHk3S66yO+ulZus0VTlabtvfWDcbkpDvCCpbj0CH+tq+8K31izzrLMa1c8d8CryesfNYNj+4EMUfPQRHf40mJTjrKm0Spcvx5SWkhfihILeir/7juTDD0fi4jzrQuludZeVQVwcrvbtwy6zMQKdZA30e8XQQuejiVQXzc6XXw6aJuiUuCJUbd7sd3PJDz9Qk58fuIwQWtTlq1YFTQNWV0/isGEB0zQqEPkRrJti27/+RWXmRvae7n+2v+zJ1k9dX0Fg24MPUfTllw3WN+dYdoDSX3+lKiuLzhMm+NyeN+NNtj/0UCNyDvweDmWirbC0pCG2TamLj8PmLrEmL/MeXlxmz3sTruKFC8m66mp63HgDe1wd3v0k0g4aSXy/fgya+1Wjyg6X3wBvjGmxM0YG4jJ2gG+m+WgCCXYCb9Oll0WgFNNgbpqSRYvoePRRDVJmnrm7tVSdl0flhg0kjaz/Q80r/QUXMGDGjJBqkXnuebTbc896VQv8Ic17a2ZIefvirqwk73//a/T+uU89ZS34qGOgfmVP+SUluMvLade9u+eCnc4TJvjOLzP0ud3L10T9pmd1bL7tdpJGjaLruec0W5m+xq57BGiY1TThupX6jY2SH5f4nEY49z/PseP5wDOI1nblNPb2mlXNeFvO2EfBCPO04FtAgI+VsuXLyTzb9wd227/+hamqYtMll7Lx/L8Fzmdp6K35suXLKfrqK9yFod0qINyLXOoz9pS6nsfNPBlaxmmns+6II8mb5XtqaHdxSeBfMH4CWf67QW6SHqxla283bjebb70t6InYwk8/ZduUKVRu3FjnhvSBFC9ciLsxx9uuW2Nf+61e51kafTGbfdz9jZLbFWKDprUIZRx8q+JpwbfCC2yaQ95bM0k48EAqaqebracyPXjrNRIyzznX5/qqbduI79WLyuzNxO/VK+T8TFkZkpISJJHv4Fi6bFnIN5moVdsK2zZl981dtj3woGfUSNGcOeQfdhhdzwlyTsNLZVYWVd6Bpwnv4ercHRTOnk3pkiXs+3Xwaa3TTxobNE352rXkzZxJ/sxZdD0/vGkGAsk49VT6TZtGfP1fgAG4A8wXX394qSARvX9ya+K8AO/2OsnaBjTmJObWO4KPOPFny223sc+noY3SqVi7NqR03q3v9ccex96vv86miy+me4Qnx6o9mVb/9oob/3ZBZPKv1/orXrCAruecHfKQyfQT/xJCqtDyqsywp22orCRt+IiQ9glmw4SJu/OPYDdDxbr1FHz4EXtcNclvmrWHHNq0QuzXINyraIsWLCAuOdlPntb5r6ptsR+Z5E+gUTQXGGNm2MtHGGO+99p2nTEmdndCCGB3C75tBPjcZ55t0v7hjteuWLc+eCKbr8nPfHHX626pvQ1cyZLIXlFa+2Xofc6i9NfwLxZqDWp/WTSl39pbZbb/wQJRUe99Gd7zaBjEa0e4mJrwZrDMvvoaH9nvzn/DGWcGzSN97Dg6jR9Hj+uvr7O+PC20BlBTBIqCN3st158cOxJnB6NC2lgLvql8jUIJpv7t1Hz2x0b6hiNNHJJa+PnnPteHOp96ozSiD75umvCLLFuxgtWpQ6mK4Hj3gs8+I/2EE5qeUSiNiUa+b7KuupptDzzoMw+DodRuLBR+8UX9XcMXZsw7qlsAACAASURBVKOoMjOTHS+82GD9hokTfaSOrEBRUPws+3rcYsR5RtG02Cq2KFtuCz4tbP7b79R5vHb0wXUe+wqe1bm5FIbYleOX1wcp0CXxnuQBTvxtvvmWptUlwnxNX9GAr6kKqgOfXMyz7wccbAjvjqmhD7Es93FNSEmQKXvDVfL993UehzvUtXjhwgZdZL4UzZkT9lXP9W2tPe/iI8QEmsco+++7W/BVW7c2qQ6hChTgjZ9lX49bjN3j4LUFHwnGmLqXm9eu9xpPjLvh22HLXY2fi672DjfeH4Ktd/9fg3o1qFMM5osJpHjBAnb4uZVd9k03+1zvzdeImrxZjR9a6i336afDmDM9vI974Zwv2XjBhWHtU/rTT2Glb4rsyZObNpVEgF+T3vMsucvK6vy69b6Hc8bE0xpffhgCnWRNFZEVWN9T+9rL2I/3iXrNGiG+d++6V7KqJvM3n86aAw6kz9NPk3zkET63m4rQh9GV+hme528q2PI1a+pcQdiS5T75FB2POaZR+5avWOG5XmHjhRfR7eKLg14YF2k1xSV+b3Ljz+Ybb4xSbULkaxRNPRWrIzBLZJDviLSDRja8NsQW6nDipgoU4FvXLVFsu+ei0S6akAQ5TpUb/F+kk/uf/7D5xhtJ9nFRVTiyw5yYacNppzepvOZWvHBhg3VCaO3idYcd7lneNX068f33jlzFQlDwgY/J2KIkYndhCuGzH+6Xli8li4Lf47apU3U0VaArWevcokhEugNHA5uMMVE8M9U0YvfB12gLPiTBLxDy/2GpHTNf8q2P/tiWdNl7K7At1KkMgh3WCDZsKjI2sP0hP/cgbowovSeqA81LA1Gb2C3WwTsUfqOgiMwWkf3t5b2AlVijZ/4nIjH+Deaf9sFHWCO/KP1dSOUEkWhp1g91eW+EOO1CM96oelsruXuR968coEGbJNg9XGtVZm5sMGS3vjrnnlqBQJ/egcaY2itCLgXmGmNOBQ6hBQ+T9HTR6CiaiKja1jxn+9ua+lMttEThnvis2raN1UP3i1j5VZFqIYc4rUHF6tUQJIDvCjYNdAsTKMB7P9M/A58DGGOKgOZrRoSptgVf42odJ+FauoL3mq8PNhqqc3Mj17fbAlRlZwdPFCPZk6+NaDfM+qMbd3I6mnIefTTWVQhLoJOsWSLyd6x54EcCcwBEJBGIb4a6hc3VpTPt7G/r6lYyykJFV0WAk8ROFNULt4IIPm1185yXieRNvVu7QC34y4FhwCXAOcaY2vFZhwKvRrlejdLnsceI0wCvvNS/H6iKncLPI3AVaRDZN95EwcefRL2c1iLQKJocoMFs9saY+UDLuB9VPa5OnWjnrg3wjptHTTVC1lXh3ZBBtW5Fc+bEugotSqDJxgJ+DRpjfN++Jsba1VhXmdVoC14p1cYFauYeBmQBM4EltOD5Z7xpH7xSSlkCBfhewInAecD5wGfATGNM426D3kx298FrF41Sqm3ze5LVGFNjjJljjLkY68TqemCBiFwXSsYi0k9E5ovIKhH5Q0RuiFCdA9IWvFJKWQI2c0WkA3AyVit+APAs8GGIeVcDtxhjfhGRFGCZiMw1xgQbS9Uk2gevlFKWQCdZ3wD2x7rA6T6vq1pDYozZCmy1l4tEZDXQB4hygLdb8Hqhk1KqjQs0Dv4CYDBwA7BYRArtvyIRCWuuSxEZAByEdbK2/rZJIrJURJbm5uaGk61P2gevlFKWQOPgIzJbl4h0BN4HbjTGNPhiMMa8DLwMMHr06CZf6qZ98EopZYnqlIsiEo8V3N80xnwQzbJqaR+8UkpZohbgxZoQYhqw2hjzVLTKqU9b8EopZYlmC/4I4ELgeBFZbv+Nj2J5gPbBK6VUrahFQWPMImJw9at20SillMVxtz3SLhqllLI4LsAL4Kqp0QCvlGrzHBfgwWrFax+8Uqqtc1SAdyUmAlY/vPbBK6XaOkcF+LiUFKC2Ba8BXinVtjkqwNeK0wCvlFLODPDaB6+UUg4N8B2qKqmMbx/raiilVEw5MsAnVpRT1qFDrKuhlFIx5eAAnxDraiilVEw5M8CXa4BXSilnBviKckoTNMArpdo2xwZ4bcErpdo6DfBKKeVQjgzwSXaAb/L9/5RSqhVzZIDvWFqCOy6OksSkWFdFKaVixpEBvueuHQBs77ZHjGuilFKx48wAv9MK8Nu694hxTZRSKnYcGeB779gOwP9dc2uMa6KUUrHjyADfuaTYs3zcizNjWBOllIodRwZ4gDfuvcmzfOfk2yhrr3PTKKXaFscG+H452/jo1isB+PGAkYx/5rXYVkgppZqZYwM8WF01PXfmeh67RWJYG6WUal6ODvAAb/3zBs/yWG3FK6XaEMcHeJcxvGkH+ar49nrSVSnVZjg+wAP03pHDXdOf8zw+/vk3KdW5apRSDtcmAjzAiT9/z5SX/w2Acbk4+elXWT54aIxrpZRS0dNmAjzAMb/+xLXvvO55fNPN93DNP+6nOCExhrVSSqnoaFMBHuCs+XO46c3/eh6vGTCIU/89nR/2P4hinZxMKeUgbS7AA0xY9A2f3nx5nXV3XXs7pz41jYvufYI5hx4NwBN/u5Ifh43wpKls147KdvF19tuV0ll/ASilWiQxpuXMmj569GizdOnSJuWxOjW8fvUZYycybeK5AdN8cPtVrOs7gH9cf6dn3fxrzgOsqRA6lhbz6S1XUhEfT3n7BBIrygFD++pqn/kVJybRsaw0rHqG441xp1MZH8+g7I10KSpkxLrVUSurpflm9OEcsvJXOpaXxboqISlITmHGuNOY9OFbxNfUxKQO1a44BEOc2x0wXdaevZg75kgunf0eekWJf6sGDmLVgEGcNX9OWPsNXdO4z6mILDPGjPa1rU224L1dMOdj5l1zHpPffcNvmjMee6lOcAe45J+PM/3UvwJQnNSR416cydhn3+C0J17mpP+8wUn/+R+PXHQ1x704k+NenMmkOx9kc4+eLBh5CKc+NY2vDz4cAyxNPYApV1jDODN79WFd3wF1yimPb8/S1AP4fd8hgHWx1vau3QHYsseeLDxoDHMOPZrMXn2YMXYile3ieXXC2bw57nTuu/JGbrr5Hk9eW/bYkz8GDqYkIZFqV1ydcr4ZfTgFyR2pcTV8S+zq1JmShERWDRxETtdugPUm/vVP+3nSbOjdl6mnn48BDDDliht44vwrPNuLE5PqjFwqj2+PW4Scrt047sWZZPbq4/f417rrmls549Gpnsc1LledKSg29urNA5f/nUcuvsazzgC/DUpt1M1ffhw2grHPvNZgxFVul26e16MwKZmyDh3I7NWnzoV0mb368OmRx1MVV/c41/fy6efy3p/Hs2Dkobufl0id+mbt2YsalwtjbwtFQXJHXjzjbw1eZ2/GTnfi8zM44fk3Ax6jH4eN4KL7/s3/Tj6TXZ26hFSHSLhn0o28d9zYJuWxqedevDLxnJDeA18cdkyDz2C4rr39fp4/+2Kf25YNGUZlu3Z11u1K6Ry1izDbfAu+vor4eB689Dq+O2hMk/JpDfpvyWZj774+tw1LX0uHqgqWD94Pd5Ag5W3frEy2de9BSVIyANe+8zpJ5eU8ftFVnjQTvp3LJ0efSGrmetYMGORZf9CalRQmdyS93wAAnn7yPm685d46+wD8a+qTuF0unj7vMvJTOtO5qJCClE4c/ttSFg/f3ZB56t/38/HRJ7Jw1O7g+Y/XX+R/48/goLQ/wBjOm/spPXfuYN7ow4hzu/nz0sWA9aE78zHry+T5R/+PfTdvoiQxifyOnbj8n495npv3B/nyj2dxzC9L2NKjJ3dcdwcAp8+fwyWz3yPO7ebeSTdx9fszGLR5E7s6dSana3euueNBAG6Z8QpHrFhKXE0NE5/8L3/amMHDzz/Ge38ex8yTJnL23Nm0q6nhrbET+ejWSXQsK6EyPp7EigpuuOkecrp157JP3qFvzjbW9+vPyn2H8NWhR9Nj105O+HkRSeVlXDDnYzb17M3FU57k/hef4Pvho5lz+LGe+t//4hMM2bSBjD796FZQwKDsTNL79qdrYQFnPfqiJ92DLzxOz107SCktpiC5Ew9dOpl7X3mGTqXF5HTtzsKDDqFrUSFH/vYzBuhSXESy/YtqZ6cudCvMZ8mwEXQuLmLAtmwSKyqYO+ZIFh40hvtfegrB+lWR16kzZz/8vKfMwZs20KMgj/suv57Dfv+FboUF3HbDXfz168844adFZPTZm/02rGPe6MOpiG/PrJMmcMuMV5gx7jS2d+/B1IfvZsimDAxw9R0PsteOHKb89xlqXC429erNwC3Znutkvpl8Pr/vO4Th69c0eI/XHsOhG9Yx6cOZdC/Io/eOHBYNH81XhxzleQ/OvPvv9LLvTQGwvm9/rrz7ESYu/IpLZr9HVs/eFHRM4Z9X38LfvviQJx+7r0FZoQjUgtcAH4JVAwfx0dEnMtfum1dKqUjbdtyI4Il8CBTg2/laGQkiMh04BcgxxuwfrXKaw34b1rPfhvXc9fqLwRP7UBUXR37HTriMYUPvfnSorKAkMYkdXbrRobKCjD578+uQYWzdY0+GbljP5j17kd1zrwg/C6VUS2aMQSLcVRO1AA+8BjwH+O/cbiPia2roUZAHQPfC/IYJfv6+mWvU8hjAiCDGWP2RIhj7VJ7b5cIIuNxuqtrFWycEa9y4RTAuIaGiguKkZCri21MRH091u3YYhDh3DR2qKinrkIBbXLiMm112F0FeSmd2depMn9ztFCSn0L66ihqXi/bV1eR3TKFDZSWdS4rJT0khvrqaivj2lCYkUpKQSOeSIvJSOtOupobEinJKEpPI6rkX8dVV5KV0JrGinN47coivrqI6Lo4te/Skql083QvyqGjfnl2dutBrZy47O3dhxaChpG5Mxy0uqtq1Y+NefTjkj+W0q67G7XKxqWdvRq1ZyaqBg0moLGdTrz5k7bkX7WpqqIlzMWRjBp2Li+hYWsLyIcOIr65iWPpavjtoDGUdEui9YzuDsjKZfdQJALSrrqba7gN2ud3svz6NbXv0oCQxiW4FeWT5OBeSXFqCEaE0yDDi2q4yl9uN2z6Xs/fWzWzaq26egzdlsG7vfeqs894nkFGrf2fZ0ANIKC+nPKFxV6Mnl5Z4uhBbilce+Ady3JcRzzeqXTQiMgCYHWoLvqV20SilVLQ5chSNiEwSkaUisjQ3Nzf4DkoppUIS8wBvjHnZGDPaGDO6Rw+9SbZSSkVKzAN8pHW77LJYV0EppVoExwX4zqecHOsqKKVUixC1AC8iM4EfgCEiki0ilwfbJ0IFN0sxSinV0kVtmKQx5rxo5R2QBnillAIc2EWjlFLK4rgA365nz1hXQSmlWgTnBfiuXWNdBaWUahEcF+CVUkpZNMArpZRDaYBXSimH0gCvlFIOpQFeKaUcSgO8Uko5lAZ4pZRyKA3wSinlUBrglVLKoTTAK6WUQ2mAV0oph9IAr5RSDqUBXimlHEoDvFJKOZQjA7yrY8dYV0EppWLOkQF+wNuzYl0FpZSKOUcG+Pb77BPrKiilVMw5MsCL3nhbKaWcGeCVUkq1gQDf55lnYl0FpZSKCccH+MQRwz3L7QftS8djjolhbZRSqvk4NsC3H7QvAPE9e3rW9brnHvq9NJU+Tz8NwF4PPRSTuimllDdXSkp08o1Kri3AwHfeYfD3i+qsSzr4YAA6jT2JAW/PovPppwXMI/X3Ffzp55+iVkcn2+ez2X63DVq4ICplxnXvHpV825qOf/5z2PtIUlIUahIZe7/xeszK7nbJJcETuVwMiVKccWyAdyUl0c7+wA/88AMG/7C4zuiaxOHDERF63HwzEh9P5zPOaJCHxMcTl5LCnv/4h88yJCHBs5xy0kkh1y1hv/1CTlvL1blz2PuEql3vvej9+GOex33+82yd7clHHRVSPpKYCMA+n35C+4EDabfnniQOH94gXVzXrnUe93v5pbrb99gjYDndLr+Mzmed2eCDO2DWzID79br3noDbQ9Vh6FD/dbv4Ynr9675G552w3370uOkmBn+/iNQ/VtL3heeJ61H3eOz1wP10nzQprHy936sAHY891rO879dz6ffSVM/jfs8/F3a9B8wMfOzrlO31BdLj5pvrbOt55x0h5dHzzjvoP/Mtz+Okww71mW7P224lecwYz3uzvkHz59Ht0ksDltV+333BFThUDl2z2vPXd+qLAPSaMoU9b78t4H4AfZ54PGiaxhJjTNQyD9fo0aPN0qVLY1K2u6KCnEcfI/nII8iefC1gvWi1KjMzSR87jqQxY9j7tVfBPm5rhu1PfJ8+7Dv3K9bsNwywWq8d9t2X1am+A8GQFb+RduBwXMnJSPv21OTlBazbgFkz6ZCaStWWrbhLS8k86yyf6bzruzp1KO169SLlhBPImzGjTrp+r7xC4ZdzKHjvfQCSxoyh+5VXknXllXS/8kr2vOXmOnVPPuooSr77rk4e/d96iw5/GgzV1aw99DAkPp59v/qSyqwskseM8aQzVVXsev11up53HsbtBrebuM6dKf31Vzaed76n3oVffYUrIYHE4cOpyc8n/aSxnjwSR4ygbPlyn88z7+132HbvvQCkrl5F3ptvkfLn46lIzyDriis86eL79GHQN1+zOnUors6d2XvaNNylJRQvXMiuadMBiOuxB30efZSCzz6j4P0PSBozhtKf6ras+s98i53/nUbxN98EfA3qv/auTp1wFxbWWTfwg/ep3LSJzTfeVGedrwZA0bx57Hj+Bcr/+IMB77xN4oEHUjjnSzbfeKMnTZfzziV/pnWRX1yXLnQaP564Lp1JOuRQkkaPQuLiKPrmG1yJiSQffrinjrV1dpeWYiorievSpc42f+9jf885dfUqRIS1hxxKTUGBJ92et91KzuNPMGT5r5R8/z3Jhx9O2W+/semSS4nv148uZ53FHldNomjBArKvvgawfu1tuvQyKjMyGpQHULVlC1XbtpM08iCM2427sBBJSsKUlRHn1Sgy1dWs2f8AAPb54nPKV60i8YADaL/33gCUp6VRuXEjuI3nmHa98EK6/e182g8YQPq48VRu2NDguXe/+ipcScnsMelKv8dnw5lnkTR6NLtetxokPW66idx//xuA5COPZO//vhLw+AYjIsuMMaN9bjTGtJi/UaNGmZZg1ZBUs2pIatj7FX4zz2x76OEG+WT9/XqTfsqpZuOll3m2VWzYYKoLCkxVbq4p/nGJqcjKNjvf+J8pT88wVTt3mqzrrjOrhqSaooULG5RTmZ1t0iee5sk/WH19pSv8+muzakiqWT9uvKnOyzNut9sUfPWVcVdUGGOMyXn2P570m6662hQvWWLK/vjDVGZnm4oNG+rkX5GZaap27Aj7eNWUlJia0tKgdd5w/t88y2mHHNog7cZLL23w/Iu+W2RWDUk16/7yF+v/8X82xhhTuny5qdy+vUEe1QUFpqakxBhjTP6ns82qIakm+6abTU1Jidl4xZV1jl11fr7JvPAiU/D556Zs9WpTtibNrBqSajZeeqknv5znnjOrhqSakp9+MjtefdWq55W789kyZYon7a533jHrTjgx6PGqLiw0u955x7jd7gbHKf3UCdYxLS8Pmk/9ff1tW3vMsXXS1f5V7dhhytLSGuyT/8mnpnT58t2PZ1vHcfVBI/2WU/z992bVkFSTecklddavPeZYs+2xx6znXVTsKTvzwotCfn71VRcVmeqCgqDpcl+calYNSTW5L7zgWef9HijPyDC7Zr1tKrOzwyo/6/obTMEXXxhjdh/TXTNnhfckfACWGj8xNeZB3fuvpQT4ogULTOmK35ucT0Vmpin99dcI1Mi3wrlzTcHnn5uSX34xFRs3+k1XvHixKfr2O1O5fbsnuLndbpP34Yemxg7ovpSvX2+2PfKoqcrJiXjdg6n9AFQXFJjK7Gyz9qijzaohqabgs88apK0pL29Qx5rSUpP5twtMyS+/mFVDUk3Of54LuezafXZMm96gPv64a2rqBF63222q8/PrpClaZH3pFH79dcDjHo7CefOs4/Lll2HvG+g5FXwxx1Ru2WKMMaZszRpT/OMSs+X//mlyX3o5rDKqcnNNTUWFqdq1y+f22i9i78ZPoLpG8/NUq6a01Gx76OE6jY/qggKz4dzz6nyBNcWqIalm3Z9PqPOeaaxAAV67aFSLVPztt8T360eHgQM968rT0kgYMiTsvExlJcTHh3WFc3naWjr8abBnn4JPZ9Nuzz1JPmRMkD1bj/pdNLFQsX49Gaecyh7XXUeP666NWT2am6mqgrg4JEjffigCddFogFeqjSr54QfiunUnYcifYlqPiowM2g8YEJFg1xYFCvDtmrsySqmWIfmww2JdBQA66OSAUaNfmUop5VAa4JVSyqGiGuBFZKyIpInIehEJ7QoGpZRSERG1AC8iccDzwDhgP+A8EQn/Ek6llFKNEs0W/BhgvTEmwxhTCcwCJkaxPKWUUl6iOYqmD5Dl9TgbOKR+IhGZBNROrFEsImmNLG8PYEcj920r9BiFRo9TaPQ4Bdccx6i/vw0xHyZpjHkZeLmp+YjIUn9jQZVFj1Fo9DiFRo9TcLE+RtHsotkM9PN63Ndep5RSqhlEM8D/DAwWkYEi0h44F/gkiuUppZTyErUuGmNMtYhcB3wJxAHTjTF/RKs8ItDN0wboMQqNHqfQ6HEKLqbHqEXNRaOUUipy9EpWpZRyKA3wSinlUK0+wLeV6RBEZLqI5IjISq913URkroiss/93tdeLiDxrH5MVIjLSa5+L7fTrRORir/WjROR3e59nxZ4I3V8ZLZGI9BOR+SKySkT+EJEb7PV6nLyISIKI/CQiv9nH6T57/UARWWI/t7ftwRGISAf78Xp7+wCvvO6016eJyEle631+Lv2V0VKJSJyI/Cois+3HresY+bsTSGv4wzp5mw7sA7QHfgP2i3W9ovRcjwZGAiu91j0G3GEv3wE8ai+PB74ABDgUWGKv7wZk2P+72std7W0/2WnF3ndcoDJa4h+wFzDSXk4B1mJNk6HHqe5xEqCjvRwPLLGf0zvAufb6qcA19vJkYKq9fC7wtr28n/2Z6wAMtD+LcYE+l/7KaKl/wM3AW8DsQPVvqcco5gewiQf/MOBLr8d3AnfGul5RfL4DqBvg04C97OW9gDR7+SXgvPrpgPOAl7zWv2Sv2wtY47Xek85fGa3hD/gYOFGPU8BjlAT8gnWV+Q6gnb3e89nCGgl3mL3czk4n9T9vten8fS7tfXyW0RL/sK7d+QY4HpgdqP4t9Ri19i4aX9Mh9IlRXWKhpzFmq728DehpL/s7LoHWZ/tYH6iMFs3+iXwQVutUj1M9dtfDciAHmIvVmsw3xlTbSbyfm+d42NsLgO6Ef/y6ByijJXoauB1w248D1b9FHqPWHuCVzVhf91Ed89ocZUSCiHQE3gduNMYUem/T42QxxtQYY0ZgtVLHAKkxrlKLIiKnADnGmGWxrktTtPYA39anQ9guInsB2P9z7PX+jkug9X19rA9URoskIvFYwf1NY8wH9mo9Tn4YY/KB+VhdAV1EpPbiR+/n5jke9vbOwE7CP347A5TR0hwBTBCRTKyZcI8HnqGVHaPWHuDb+nQInwC1Izwuxupzrl1/kT1K5FCgwO4++BL4i4h0tUd5/AWrf28rUCgih9qjQi6ql5evMlocu+7TgNXGmKe8Nulx8iIiPUSki72ciHWeYjVWoD/LTlb/ONU+t7OAefavlE+Ac+0RJAOBwVgnoX1+Lu19/JXRohhj7jTG9DXGDMCq/zxjzN9obcco1icyInAiZDzWaIl04O5Y1yeKz3MmsBWowuqXuxyrv+4bYB3wNdDNTitYN1tJB34HRnvlcxmw3v671Gv9aGClvc9z7L7K2WcZLfEPOBKra2QFsNz+G6/HqcFxOhD41T5OK4F77PX7YAWf9cC7QAd7fYL9eL29fR+vvO62j0Ua9ogie73Pz6W/MlryH3Asu0fRtKpjpFMVKKWUQ7X2LhqllFJ+aIBXSimH0gCvlFIOpQFeKaUcSgO8Uko5lAZ41WKJSHcRWW7/bRORzV6PA86wJyKjReTZEMpYHLkaN8i7i4hMjlb+SgWjwyRVqyAiU4BiY8wTXuvamd1zdrQ49nw4s40x+8e4KqqN0ha8alVE5DURmSoiS4DHRGSMiPxgz9m9WESG2OmO9ZrDe4pY8+kvEJEMEbneK79ir/QLROQ9EVkjIm/aV6siIuPtdcvEmgN+to96DRNrjvXlYs0tPxh4BNjXXve4ne42EfnZTlM7D/sArzJX23VIsrc9Itb89itE5In65SoVSNRuuq1UFPUFDjfG1IhIJ+AoY93k/QTgIeBMH/ukAsdhzROfJiIvGmOq6qU5CBgGbAG+B44QkaVY0wUfbYzZICIz/dTpauAZY8ybdvdRHNa88Psba1IvROQvWJeqj8G6ivYTETka2AQMAS43xnwvItOBySLyKnA6kGqMMbXTCygVKm3Bq9boXWNMjb3cGXhXrDtd/RsrQPvymTGmwhizA2siMF/T+f5kjMk2xrixpjkYgPXFkGGM2WCn8RfgfwDuEpF/AP2NMWU+0vzF/vsVaw72VKyAD5BljPneXp6BNe1CAVAOTBORM4BSP2Ur5ZMGeNUalXgt3w/Mt/u5T8WaE8SXCq/lGnz/eg0ljU/GmLeACUAZ8LmIHO8jmQAPG2NG2H+DjDHTarNomKWpxmrtvwecAswJtT5KgQZ41fp1Zvd0qpdEIf80YB/ZfY/Nc3wlEpF9sFr6z2LN/ncgUITVJVTrS+AysearR0T6iMie9ra9ReQwe/l8YJGdrrMx5nPgJmB4xJ6VahM0wKvW7jHgYRH5lSicU7K7WiYDc0RkGVbQLvCR9GxgpVh3SdofeMMYsxP4XkRWisjjxpivsO7v+YOI/I7VMq/9AkgDrhWR1Vj3gX3R3jZbRFYAi7DuD6pUyHSYpFJBlKK6GwAAAFdJREFUiEhHY0yxParmeWCdMebfEcx/ADqcUkWBtuCVCu5Ku2X+B1aX0Esxro9SIdEWvFJKOZS24JVSyqE0wCullENpgFdKKYfSAK+UUg6lAV4ppRzq/wEaMdaefjslBgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "3iZTVn5WQFpX",
        "outputId": "74cb0c99-e6c4-4e63-fc84-cd62ab56da23"
      },
      "source": [
        "del model\n",
        "model = NeuralNet(tr_set.dataset.dim).to(device)\n",
        "ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n",
        "model.load_state_dict(ckpt)\n",
        "plot_pred(dv_set, model, device)  # Show prediction on the validation set"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQikz3IPiyPf"
      },
      "source": [
        "# **Testing**\n",
        "The predictions of your model on testing set will be stored at `pred.csv`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8cTuQjQQOon",
        "outputId": "44923e48-78a0-4276-843c-cd5f7bb3bc08"
      },
      "source": [
        "def save_pred(preds, file):\n",
        "    ''' Save predictions to specified file '''\n",
        "    print('Saving results to {}'.format(file))\n",
        "    with open(file, 'w') as fp:\n",
        "        writer = csv.writer(fp)\n",
        "        writer.writerow(['id', 'tested_positive'])\n",
        "        for i, p in enumerate(preds):\n",
        "            writer.writerow([i, p])\n",
        "\n",
        "preds = test(tt_set, model, device)  # predict COVID-19 cases with your model\n",
        "save_pred(preds, 'pred.csv')         # save prediction file to pred.csv"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving results to pred.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfrVxqJanGpE"
      },
      "source": [
        "# **Hints**\n",
        "\n",
        "## **Simple Baseline**\n",
        "* Run sample code\n",
        "\n",
        "## **Medium Baseline**\n",
        "* Feature selection: 40 states + 2 `tested_positive` (`TODO` in dataset)\n",
        "\n",
        "## **Strong Baseline**\n",
        "* Feature selection (what other features are useful?)\n",
        "* DNN architecture (layers? dimension? activation function?)\n",
        "* Training (mini-batch? optimizer? learning rate?)\n",
        "* L2 regularization\n",
        "* There are some mistakes in the sample code, can you find them?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tmCwXgpot3t"
      },
      "source": [
        "# **Reference**\n",
        "This code is completely written by Heng-Jui Chang @ NTUEE.  \n",
        "Copying or reusing this code is required to specify the original author. \n",
        "\n",
        "E.g.  \n",
        "Source: Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)\n"
      ]
    }
  ]
}